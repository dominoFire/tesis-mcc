\chapter{Introducción}

El mundo digital dominado por datos requiere la utilización de algoritmos, tecnologías y mecanismos que permitan orquestar procesamientos de grandes volúmenes de datos, los cuales pueden tardar horas e, incluso, días en completarse. Aún así, el diseño de la aplicación, junto con el flujo de trabajo requiere un esfuerzo considerable cuando se realizan estas aplicaciones.

Ahora bien, sería deseable desarrollar una plataforma que permita distribuir estos flujos de trabajo computacionalmente intensivos en un sistema distribuído con el fin de disminuir el tiempo de ejecución del flujo. También, es deseable disminuir el presupuesto utilizado, ya que es muy común que en los modelos de cómputo en la nube se tenga un modelo económico en que se cobre por utilizar estos servicios.

En este trabajo se muestra el desarrollo de esta plataforma de ejecución de flujos de trabajo intensivo en datos con aplicación en cómputo en la nube. También se muestra el marco teórico necesario para el desarrollo de este proyecto.

Primero, empezaremos por describir el modelo de costos de cómputo en la nube, marcado por acuerdos de nivel de servicio, y se describirá un mecanismo para poder

Luego, describiremos cómo hacer benchmarking dentro de plataformas de cómputo en la nube. Se sugiere utilizar el benchmark proporcionado por LINPACK, ya que éste puede aproximar el rendimiento de un sólo núcleo y varios núcleos. En la tesis de XXX et al. se puede mostrar. Luego describiremos el algoritmo de planificación de flujos de trabajo. Luego describiremos el mecanismo para poner las tareas en de. Luego, compararemos con soluciones existentes como Aneka, HTCondor y Pegasus.


\section{Descripción del problema}

Se tiene un flujo de trabajo definido por $W = (T, D)$, donde $T$ es el conjunto de tareas del flujo de trabajo y $D$ es el conjunto de dependencias que existen entre las tareas del flujo de trabajo. Se desea planificar las tareas en un conjunto de recursos $R$ en la nube de diferente capacidad, los cuales están conectados entre sí por medio de una red privada virtual. Se tiene una función $F: W \times R \mapsto (\mathcal{R}^{+} \times {R}^{+}) $ la cual asocia un costo y un tiempo total de ejecución a una planificación de este flujo de trabajo con el conjunto de recursos dato. Se requiere minimizar la función $F$ tanto en costo como en tiempo. Cabe aclarar que, a diferencia del problema clásico de planificación de flujos de trabajo donde se tiene


\section{Lineamientos de diseño}

Desarrollar un sistema de administración de flujos de trabajo es como desarrollar una receta para hacer chocolate: hay muchas formas y modalidades de hacerlo. Sin embargo, se pueden ver algunos patrones de uso o generalidades que quisiéramos observar en el sistema administrador de flujos de trabajo. A continuación, se listarán los lineamentos de diseño deseables en el sistema administrador de flujos de trabajo.



\subsection{El flujo como centro de la aplicación}

Los sistemas de cómputo distribuido tienen inherentes una complexidad que crece más conforme mayores capacidades de agregan a éstos. Los científicos y personas especialistas de algún dominio de conocimiento cada vez tienen menos tiempo para aprender los detalles del funcionamiento de estos sistemas distribuidos. Por otro lado, dibujar diagramas que describan la secuencia de ejecución de los programas es más intuitivo. Y un flujo de trabajo bien puede expresarse a través de estos diagramas. De esta forma, especificar el flujo de trabajo es el pilar que describe los procesos a ejecutar. Por otro lado, el flujo de trabajo aporta información que ayuda a la paralelización y ejecución distribuida del mismo.



\subsection{Orientado a nubes}

Aunque se pueden ejecutar Open Grid Scheduler, HTCondor, programas MPI y aplicaciones basadas en MapReduce y cómputo distribuido en gráficas, éstos funcionan muy bien en entornos de una sola computadora con gran capacidad o en grids institucionales. Sin embargo, cuando se utilizan estos programas en enfoques como la nube, surgen algunas eventualidades, a saber: 1) es más difícil supervisar estos entornos por el hecho de la insfraestrucutra no es \emph{on-premise} o, en el caso de grids comunitarios, se conoce a ciencia cierta el funcionamiento del sistema y, 2) hay un costo monetario por utilizar estos recursos que está explícitamente establecido, el cual es deseable minimizar. Además, otra característica importante de la nube, a saber, la utilización de máquinas virutales, hace que el rendimiento del sistema distribuido en general pueda escalarse prácticamente sin límites. Por ello, es deseable ejecutar el flujo de trabajo en el menor tiempo posible, respetando un presupuesto asignado. Esta flexibilidad sólo es posible encontrarla actualmente en las infraestructuras de servicios de cómputo en la nube. Por esta razón, el sistema administrador de flujos de trabajo tiene que estar fuertemente orientado a trabajar en la nube.



\subsection{Intensivo en datos}

Como se ha dicho en la introducción, las cargas de trabajo que administran estos sistemas usualmente generan enormes cantidades de datos, que son desde logs de operación, archivos intermedios de resultados o volcados de memoria en caso de que ocurra algún error. Así, manejar datos es primordial en nuestra solucíón. Este requerimiento se puede cumplir utilizando sistemas de archivos distribuidos con énfasis en la tasa de rendimiento de datos guardados.


\subsection{Portable entre nubes}

Esto con el fin de tener la libertad de escoger la plataforma de cómputo en la nube conveniente a las necesidades del flujo.
%Aunque dudo que este requerimiento pueda cumplirse, debido a las abstracciones necesarias que deben hacerse en el software


\subsection{Simple}

Las interacciones con el usuario deben ser simples



\subsection{Basado en estándares}
